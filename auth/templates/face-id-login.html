<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!--add this code to using tailwind -->
    <link rel="stylesheet" href="../../static/output.css" />
    <title>DG Games</title>
    <style>
      canvas {
        position: absolute;
        top: 0;
      }
    </style>
  </head>
  <body class="relative">
    <video autoplay id="video" width="400" height="280"></video>
    <br />
    <button onclick="capture()">Capture your face</button>
    <br />

    <form action="{{ url_for('auth.register_face_id') }}" method="post">
      <input type="text" id="name" required name="name" />
      <input type="text" id="photo" required name="photo" hidden />

      <button type="button" onclick="register()">Register</button>
    </form>
    <br />

    <div hidden>
      {% for registered_face in registered_faces%}
      <p class="registered_face_username">{{registered_face.username}}</p>
      <p class="registered_face_photo">{{registered_face.photo}}</p>
      {% endfor %}
    </div>

    <script
      src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.js"
      integrity="sha256-JOJ7NmVm2chxYZ1KPcAYd2bwVK7NaFj9QKMp7DClews="
      crossorigin="anonymous"
    ></script>

    <script>
      var video = document.getElementById("video");
      var registeredFaceUsernames = document.getElementsByClassName(
        "registered_face_username"
      );
      var registeredFacePhotos = document.getElementsByClassName(
        "registered_face_photo"
      );

      let nameInput;

      async function loadTrainingData() {
        let labels = [];
        let photos = [];

        Array.from(registeredFaceUsernames).forEach((username) => {
          labels.push(username.innerText);
        });

        Array.from(registeredFacePhotos).forEach((photo) => {
          photos.push(photo.innerText);
        });

        const faceDescriptors = [];

        labels.length > 0 &&
          labels.map((label) => {
            const descriptors = [];

            photos.length > 0 &&
              photos.map(async (photo) => {
                let image = document.createElement("img");
                image.setAttribute("src", photo);

                const detections = await faceapi
                  .detectSingleFace(image)
                  .withFaceLandmarks()
                  .withFaceDescriptor();

                if (detections) {
                  console.log("detections", detections);
                  descriptors.push(detections.descriptor);
                }
              });

            faceDescriptors.push(
              new faceapi.LabeledFaceDescriptors(label, descriptors)
            );
          });

        return faceDescriptors;
      }

      let faceMatcher;

      async function loadModelFaceApi() {
        await Promise.all([
          await faceapi.nets.ssdMobilenetv1.loadFromUri("/static/models"),
          await faceapi.nets.faceRecognitionNet.loadFromUri("/static/models"),
          await faceapi.nets.tinyFaceDetector.loadFromUri("/static/models"),
          await faceapi.nets.faceLandmark68Net.loadFromUri("/static/models"),
        ]);

        const trainingData = await loadTrainingData();

        faceMatcher = new faceapi.FaceMatcher(trainingData, 0.6);

        console.log("faceMatcher", faceMatcher);
      }

      function init() {
        nameInput = document.getElementById("name");
        photoInput = document.getElementById("photo");

        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then((stream) => {
            video.srcObject = stream;
          })
          .catch((error) => {
            console.log(error);
          });
      }

      video.addEventListener("play", async () => {
        const canvas = faceapi.createCanvasFromMedia(video);
        document.body.append(canvas);

        const displaySize = { width: video.width, height: video.height };

        faceapi.matchDimensions(canvas, displaySize);

        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();

          const resizedDetections = faceapi.resizeResults(
            detections,
            displaySize
          );

          const context = canvas.getContext('2d');
          context.clearRect(0, 0, canvas.width, canvas.height);
          context.canvas.willReadFrequently = true;
          
          resizedDetections.forEach((resizedDetection, i) => {
            const box = resizedDetection.detection.box;
            const descriptor = resizedDetection.descriptor; // Get the descriptor from the resizedDetection

            const drawBox = new faceapi.draw.DrawBox(box, {
              label: faceMatcher.findBestMatch(descriptor).toString(), // Use the descriptor here
            });

            drawBox.draw(canvas);
          });
        }, 100);
      });

      loadModelFaceApi().then(init);
    </script>
  </body>
</html>
